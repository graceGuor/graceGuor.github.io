<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Grace</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-04-23T04:11:58.882Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Grace</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>优化算法</title>
    <link href="http://yoursite.com/2019/04/11/Optimizer/"/>
    <id>http://yoursite.com/2019/04/11/Optimizer/</id>
    <published>2019-04-11T11:12:03.000Z</published>
    <updated>2019-04-23T04:11:58.882Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;  本文介绍机器学习中不同优化算法之间的差异。&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Optimizer" scheme="http://yoursite.com/tags/Optimizer/"/>
    
      <category term="优化" scheme="http://yoursite.com/tags/%E4%BC%98%E5%8C%96/"/>
    
      <category term="SGD" scheme="http://yoursite.com/tags/SGD/"/>
    
      <category term="Momentum" scheme="http://yoursite.com/tags/Momentum/"/>
    
      <category term="NAG" scheme="http://yoursite.com/tags/NAG/"/>
    
      <category term="Adam" scheme="http://yoursite.com/tags/Adam/"/>
    
  </entry>
  
  <entry>
    <title>语言模型</title>
    <link href="http://yoursite.com/2019/03/24/%E7%BB%9F%E8%AE%A1%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86C5/"/>
    <id>http://yoursite.com/2019/03/24/统计自然语言处理C5/</id>
    <published>2019-03-23T16:00:00.000Z</published>
    <updated>2019-04-11T12:15:43.414Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;  语言模型（language model，LM）目前主要采用的是n元语法模型（n-gram model），这种模型构建简单、直接，但同时也因为数据缺乏而必须采取平滑（smoothing）算法。&lt;br&gt;
  本章主要介绍n元语法的基本概念和几种常用的数据平滑方法。&lt;/p&gt;
    
    </summary>
    
      <category term="统计自然语言处理" scheme="http://yoursite.com/categories/%E7%BB%9F%E8%AE%A1%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"/>
    
    
      <category term="NLP" scheme="http://yoursite.com/tags/NLP/"/>
    
      <category term="语言模型" scheme="http://yoursite.com/tags/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/"/>
    
      <category term="数据平滑" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E5%B9%B3%E6%BB%91/"/>
    
      <category term="n-gram" scheme="http://yoursite.com/tags/n-gram/"/>
    
  </entry>
  
  <entry>
    <title>语料库与语言知识库</title>
    <link href="http://yoursite.com/2019/03/22/%E7%BB%9F%E8%AE%A1%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86C4/"/>
    <id>http://yoursite.com/2019/03/22/统计自然语言处理C4/</id>
    <published>2019-03-22T11:12:03.000Z</published>
    <updated>2019-04-11T12:16:48.733Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;本章介绍两个语料库，英文语料库WordNet和中文语料库HowNet。&lt;/p&gt;
    
    </summary>
    
      <category term="统计自然语言处理" scheme="http://yoursite.com/categories/%E7%BB%9F%E8%AE%A1%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"/>
    
    
      <category term="NLP" scheme="http://yoursite.com/tags/NLP/"/>
    
      <category term="语料库" scheme="http://yoursite.com/tags/%E8%AF%AD%E6%96%99%E5%BA%93/"/>
    
      <category term="WordNet" scheme="http://yoursite.com/tags/WordNet/"/>
    
      <category term="HowNet" scheme="http://yoursite.com/tags/HowNet/"/>
    
  </entry>
  
  <entry>
    <title>信息论基本概念</title>
    <link href="http://yoursite.com/2019/03/17/%E7%BB%9F%E8%AE%A1%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86C2/"/>
    <id>http://yoursite.com/2019/03/17/统计自然语言处理C2/</id>
    <published>2019-03-17T11:14:50.000Z</published>
    <updated>2019-04-11T12:16:03.540Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;本章介绍信息论的一些基本概念，如熵、联合熵、条件熵、互信息、相对熵、交叉熵、困惑度，以及噪声信道模型。&lt;/p&gt;
    
    </summary>
    
      <category term="统计自然语言处理" scheme="http://yoursite.com/categories/%E7%BB%9F%E8%AE%A1%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"/>
    
    
      <category term="NLP" scheme="http://yoursite.com/tags/NLP/"/>
    
      <category term="信息论" scheme="http://yoursite.com/tags/%E4%BF%A1%E6%81%AF%E8%AE%BA/"/>
    
      <category term="熵" scheme="http://yoursite.com/tags/%E7%86%B5/"/>
    
  </entry>
  
</feed>
