<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Grace</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-04-30T08:24:45.042Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Grace</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>容量过拟合欠拟合</title>
    <link href="http://yoursite.com/2019/05/01/%E5%AE%B9%E9%87%8F%E8%BF%87%E6%8B%9F%E5%90%88%E6%AC%A0%E6%8B%9F%E5%90%88/"/>
    <id>http://yoursite.com/2019/05/01/容量过拟合欠拟合/</id>
    <published>2019-05-01T11:18:24.000Z</published>
    <updated>2019-04-30T08:24:45.042Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;  机器学习的主要挑战是我们的算法必须能够在先前未观测的新输入上表现良好，而不只是在训练集上表现良好。在先前未观测到的输入上表现良好的能力被称为泛化（generalization）。&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="容量" scheme="http://yoursite.com/tags/%E5%AE%B9%E9%87%8F/"/>
    
      <category term="过拟合" scheme="http://yoursite.com/tags/%E8%BF%87%E6%8B%9F%E5%90%88/"/>
    
      <category term="欠拟合" scheme="http://yoursite.com/tags/%E6%AC%A0%E6%8B%9F%E5%90%88/"/>
    
  </entry>
  
  <entry>
    <title>学习算法</title>
    <link href="http://yoursite.com/2019/04/29/%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/"/>
    <id>http://yoursite.com/2019/04/29/学习算法/</id>
    <published>2019-04-29T11:23:58.000Z</published>
    <updated>2019-04-30T08:30:38.348Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;  Mitchell (1997) 提供了一个简洁的 &lt;strong&gt;定义&lt;/strong&gt; ：‘‘对于某类  任务 $ T $ 和 性能度量 $ P $  ，一个计算机程序被认为可以从 经验 $ E $ 中学习是指，通过经验  $ E $  改进后，它在任务 $ T $ 上由性能度量 $ P $ 衡量的性能有所提升。”&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="容量" scheme="http://yoursite.com/tags/%E5%AE%B9%E9%87%8F/"/>
    
  </entry>
  
  <entry>
    <title>wct</title>
    <link href="http://yoursite.com/2019/04/23/wct/"/>
    <id>http://yoursite.com/2019/04/23/wct/</id>
    <published>2019-04-23T14:11:23.000Z</published>
    <updated>2019-04-24T10:16:52.272Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;  本文学习任意风格只需要训练一个WCT模型，而且训练过程中不需要风格图的风格转换论文&amp;quot;Universal Style Transfer via Feature Transforms&amp;quot;。&lt;/p&gt;
    
    </summary>
    
      <category term="style transfer" scheme="http://yoursite.com/categories/style-transfer/"/>
    
    
      <category term="style transfer" scheme="http://yoursite.com/tags/style-transfer/"/>
    
      <category term="WCT" scheme="http://yoursite.com/tags/WCT/"/>
    
  </entry>
  
  <entry>
    <title>style_swap</title>
    <link href="http://yoursite.com/2019/04/17/style-swap/"/>
    <id>http://yoursite.com/2019/04/17/style-swap/</id>
    <published>2019-04-17T13:38:27.000Z</published>
    <updated>2019-04-24T10:16:56.328Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;  本文学习任意风格只需要训练一个style-swap模型的风格转换论文&amp;quot;Fast Patch-based Style Transfer of Arbitrary Style&amp;quot;。&lt;/p&gt;
    
    </summary>
    
      <category term="style transfer" scheme="http://yoursite.com/categories/style-transfer/"/>
    
    
      <category term="style transfer" scheme="http://yoursite.com/tags/style-transfer/"/>
    
      <category term="style_swap" scheme="http://yoursite.com/tags/style-swap/"/>
    
  </entry>
  
  <entry>
    <title>优化算法</title>
    <link href="http://yoursite.com/2019/04/11/Optimizer/"/>
    <id>http://yoursite.com/2019/04/11/Optimizer/</id>
    <published>2019-04-11T11:12:03.000Z</published>
    <updated>2019-04-23T04:11:58.882Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;  本文介绍机器学习中不同优化算法之间的差异。&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Optimizer" scheme="http://yoursite.com/tags/Optimizer/"/>
    
      <category term="优化" scheme="http://yoursite.com/tags/%E4%BC%98%E5%8C%96/"/>
    
      <category term="SGD" scheme="http://yoursite.com/tags/SGD/"/>
    
      <category term="Momentum" scheme="http://yoursite.com/tags/Momentum/"/>
    
      <category term="NAG" scheme="http://yoursite.com/tags/NAG/"/>
    
      <category term="Adam" scheme="http://yoursite.com/tags/Adam/"/>
    
  </entry>
  
  <entry>
    <title>Gatys</title>
    <link href="http://yoursite.com/2019/04/05/Gatys/"/>
    <id>http://yoursite.com/2019/04/05/Gatys/</id>
    <published>2019-04-05T11:12:03.000Z</published>
    <updated>2019-04-24T09:18:02.405Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;  本文学习风格转换（style transfer）祖师爷Gatys的论文&amp;quot;Image Style Transfer Using Convolutional Neural Network&amp;quot;和&amp;quot;A Neural Algorithm of Artistic Style&amp;quot;。&lt;/p&gt;
    
    </summary>
    
      <category term="style transfer" scheme="http://yoursite.com/categories/style-transfer/"/>
    
    
      <category term="style transfer" scheme="http://yoursite.com/tags/style-transfer/"/>
    
      <category term="Gatys" scheme="http://yoursite.com/tags/Gatys/"/>
    
  </entry>
  
  <entry>
    <title>style transfer概述</title>
    <link href="http://yoursite.com/2019/03/27/style-transfer/"/>
    <id>http://yoursite.com/2019/03/27/style-transfer/</id>
    <published>2019-03-27T11:12:03.000Z</published>
    <updated>2019-04-24T14:04:54.408Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;  本文对风格转换（style transfer）进行概述。&lt;/p&gt;
    
    </summary>
    
      <category term="style transfer" scheme="http://yoursite.com/categories/style-transfer/"/>
    
    
      <category term="style transfer" scheme="http://yoursite.com/tags/style-transfer/"/>
    
  </entry>
  
  <entry>
    <title>语言模型</title>
    <link href="http://yoursite.com/2019/03/24/%E7%BB%9F%E8%AE%A1%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86C5/"/>
    <id>http://yoursite.com/2019/03/24/统计自然语言处理C5/</id>
    <published>2019-03-23T16:00:00.000Z</published>
    <updated>2019-04-11T12:15:43.414Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;  语言模型（language model，LM）目前主要采用的是n元语法模型（n-gram model），这种模型构建简单、直接，但同时也因为数据缺乏而必须采取平滑（smoothing）算法。&lt;br&gt;
  本章主要介绍n元语法的基本概念和几种常用的数据平滑方法。&lt;/p&gt;
    
    </summary>
    
      <category term="统计自然语言处理" scheme="http://yoursite.com/categories/%E7%BB%9F%E8%AE%A1%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"/>
    
    
      <category term="NLP" scheme="http://yoursite.com/tags/NLP/"/>
    
      <category term="语言模型" scheme="http://yoursite.com/tags/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/"/>
    
      <category term="数据平滑" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E5%B9%B3%E6%BB%91/"/>
    
      <category term="n-gram" scheme="http://yoursite.com/tags/n-gram/"/>
    
  </entry>
  
  <entry>
    <title>语料库与语言知识库</title>
    <link href="http://yoursite.com/2019/03/22/%E7%BB%9F%E8%AE%A1%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86C4/"/>
    <id>http://yoursite.com/2019/03/22/统计自然语言处理C4/</id>
    <published>2019-03-22T11:12:03.000Z</published>
    <updated>2019-04-11T12:16:48.733Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;本章介绍两个语料库，英文语料库WordNet和中文语料库HowNet。&lt;/p&gt;
    
    </summary>
    
      <category term="统计自然语言处理" scheme="http://yoursite.com/categories/%E7%BB%9F%E8%AE%A1%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"/>
    
    
      <category term="NLP" scheme="http://yoursite.com/tags/NLP/"/>
    
      <category term="语料库" scheme="http://yoursite.com/tags/%E8%AF%AD%E6%96%99%E5%BA%93/"/>
    
      <category term="WordNet" scheme="http://yoursite.com/tags/WordNet/"/>
    
      <category term="HowNet" scheme="http://yoursite.com/tags/HowNet/"/>
    
  </entry>
  
  <entry>
    <title>信息论基本概念</title>
    <link href="http://yoursite.com/2019/03/17/%E7%BB%9F%E8%AE%A1%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86C2/"/>
    <id>http://yoursite.com/2019/03/17/统计自然语言处理C2/</id>
    <published>2019-03-17T11:14:50.000Z</published>
    <updated>2019-04-30T03:10:25.715Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;本章介绍信息论的一些基本概念，如熵、联合熵、条件熵、互信息、相对熵、交叉熵、困惑度，以及噪声信道模型。&lt;/p&gt;
    
    </summary>
    
      <category term="统计自然语言处理" scheme="http://yoursite.com/categories/%E7%BB%9F%E8%AE%A1%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"/>
    
    
      <category term="NLP" scheme="http://yoursite.com/tags/NLP/"/>
    
      <category term="信息论" scheme="http://yoursite.com/tags/%E4%BF%A1%E6%81%AF%E8%AE%BA/"/>
    
      <category term="熵" scheme="http://yoursite.com/tags/%E7%86%B5/"/>
    
  </entry>
  
</feed>
